{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VRtNzIUE9WXX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pre Processing"
      ],
      "metadata": {
        "id": "z7pLP0WWM9yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Processing 1"
      ],
      "metadata": {
        "id": "VRtNzIUE9WXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-OxEU6-Ynso"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('all-vehicles-model.csv', on_bad_lines='skip', sep=';')\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "VIRHR4In9t1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0ecDUmpdz2c"
      },
      "outputs": [],
      "source": [
        "if 'Cylinders' in data.columns:\n",
        "    data['Cylinders'].fillna(0, inplace=True)\n",
        "\n",
        "if 'Electric motor' in data.columns:\n",
        "    data['Electric motor'].fillna('Not Electric', inplace=True)\n",
        "\n",
        "if 'ATV Type' in data.columns:\n",
        "    data['ATV Type'].fillna('Petrol', inplace=True)\n",
        "\n",
        "if 'Drive' in data.columns:\n",
        "    data['Drive'].fillna('All-Wheel Drive', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unnecessary_cols = [\n",
        "    'Annual Petroleum Consumption For Fuel Type1',\n",
        "    'Annual Petroleum Consumption For Fuel Type2',\n",
        "    'Time to charge at 120V',\n",
        "    'Time to charge at 240V',\n",
        "    'Unrounded City Mpg For Fuel Type1 (2)',\n",
        "    'Unrounded City Mpg For Fuel Type2',\n",
        "    'City gasoline consumption',\n",
        "    'City electricity consumption',\n",
        "    'EPA city utility factor',\n",
        "    'Co2 Fuel Type2',\n",
        "    'Co2  Tailpipe For Fuel Type2',\n",
        "    'Co2  Tailpipe For Fuel Type1',\n",
        "    'Combined Mpg For Fuel Type1',\n",
        "    'Unrounded Combined Mpg For Fuel Type1',\n",
        "    'Combined Mpg For Fuel Type2',\n",
        "    'Unrounded Combined Mpg For Fuel Type2',\n",
        "    'Combined electricity consumption',\n",
        "    'Combined gasoline consumption',\n",
        "    'EPA combined utility factor',\n",
        "    'Engine displacement',\n",
        "    'EPA model type index',\n",
        "    'EPA Fuel Economy Score',\n",
        "    'Annual Fuel Cost For Fuel Type2',\n",
        "    'GHG Score Alternative Fuel',\n",
        "    'Highway Mpg For Fuel Type1',\n",
        "    'Unrounded Highway Mpg For Fuel Type1',\n",
        "    'Highway Mpg For Fuel Type2',\n",
        "    'Unrounded Highway Mpg For Fuel Type2',\n",
        "    'Highway gasoline consumption',\n",
        "    'Highway electricity consumption',\n",
        "    'EPA highway utility factor',\n",
        "    'Hatchback luggage volume',\n",
        "    'Hatchback passenger volume',\n",
        "    '2 door luggage volume',\n",
        "    '4 door luggage volume',\n",
        "    'MPG Data',\n",
        "    'PHEV Blended',\n",
        "    '2-door passenger volume',\n",
        "    '4-door passenger volume',\n",
        "    'Range For Fuel Type1',\n",
        "    'Range  City For Fuel Type1',\n",
        "    'Range  City For Fuel Type2',\n",
        "    'Range  Highway For Fuel Type1',\n",
        "    'Range  Highway For Fuel Type2',\n",
        "    'Unadjusted City Mpg For Fuel Type1',\n",
        "    'Unadjusted City Mpg For Fuel Type2',\n",
        "    'Unadjusted Highway Mpg For Fuel Type1',\n",
        "    'Unadjusted Highway Mpg For Fuel Type2',\n",
        "    'You Save/Spend',\n",
        "    'Guzzler',\n",
        "    'Transmission descriptor',\n",
        "    'T Charger',\n",
        "    'S Charger',\n",
        "    'Epa Range For Fuel Type2',\n",
        "    'c240Dscr',\n",
        "    'charge240b',\n",
        "    'C240B Dscr',\n",
        "    'Created On',\n",
        "    'Modified On',\n",
        "    'PHEV City',\n",
        "    'PHEV Highway',\n",
        "    'PHEV Combined',\n",
        "    'City Mpg For Fuel Type2',\n",
        "    'Fuel Type2',\n",
        "    'MFR Code',\n",
        "    'Fuel Type1',\n",
        "    'Start-Stop',\n",
        "    'Engine descriptor',\n",
        "    'GHG Score'\n",
        "]\n",
        "data.drop(unnecessary_cols, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "s6-awSg5-COq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtCOVG0wCRpP"
      },
      "outputs": [],
      "source": [
        "null_data = data[data.isnull().any(axis=1)]\n",
        "data.dropna(inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Processing 2"
      ],
      "metadata": {
        "id": "qSuY1nB-_BWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Year'] = pd.to_numeric(data['Year'])"
      ],
      "metadata": {
        "id": "wv0rB_Z0D_SV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sort_values(by='Year', ascending=False, inplace=True)\n",
        "data"
      ],
      "metadata": {
        "id": "9hPCXw61Ez9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_unique = data.drop_duplicates(subset=['Model'], keep='first')\n",
        "data_unique.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "0r1cbVU-Cahn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Processing 3"
      ],
      "metadata": {
        "id": "ktow0d6WGRHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U duckduckgo_search"
      ],
      "metadata": {
        "id": "z2CfixWhMj7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from duckduckgo_search import DDGS\n",
        "cars = []\n",
        "for i in range(0, 4876):\n",
        "  car = data[\"Make\"][i] + \" \" + data[\"Model\"][i] + \" \" + data[\"Year\"][i].astype(str)\n",
        "  results = DDGS().images(\n",
        "      keywords=car,\n",
        "      region=\"wt-wt\",\n",
        "      safesearch=\"off\",\n",
        "      size=None,\n",
        "      color=\"color\",\n",
        "      type_image=\"photo\",\n",
        "      layout=\"wide\",\n",
        "      license_image=None,\n",
        "      max_results=1,\n",
        "  )\n",
        "  if len(results):\n",
        "    data.loc[data['Model'] == data[\"Model\"][i], \"Image\"] = results[0][\"image\"]\n",
        "  else:\n",
        "    cars.append(car)"
      ],
      "metadata": {
        "id": "2AqUqW8EMsBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Year'] = data['Year'].astype(str)"
      ],
      "metadata": {
        "id": "VZjdeWmslAKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre Processing 4"
      ],
      "metadata": {
        "id": "G2nOMrvJ4OiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from duckduckgo_search import DDGS\n",
        "\n",
        "cars = []\n",
        "prices = []\n",
        "\n",
        "for i in range(1006, 4876):\n",
        "  car = data[\"Make\"][i] + \" \" + data[\"Model\"][i] + \" \" + data[\"Year\"][i].astype(str) + \" price in dollars\"\n",
        "  results = DDGS().text(car, max_results=5)\n",
        "  j = 5\n",
        "  print(i)\n",
        "  print(car)\n",
        "  l = True\n",
        "  while l:\n",
        "    for k in range(0, j):\n",
        "      body_text = results[k]['body']\n",
        "      matches = re.findall(r'\\$[\\d,]{4,}(?: - \\$[\\d,]+)?', body_text)\n",
        "      if matches:\n",
        "        print(body_text)\n",
        "        print(matches[0])\n",
        "        data.loc[data['Model'] == data[\"Model\"][i], \"Price\"] = matches[0]\n",
        "        l = False\n",
        "        break\n",
        "\n",
        "    if l:\n",
        "      if j<=95:\n",
        "        j=j+5\n",
        "        results = DDGS().text(car, max_results=j)\n",
        "      else:\n",
        "        l=False"
      ],
      "metadata": {
        "id": "lJQY_DwCo4-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_csv('final_car_data.csv')"
      ],
      "metadata": {
        "id": "_7Nj-Jt4wkMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation Models"
      ],
      "metadata": {
        "id": "VL8EC-OTwQcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Embeddings"
      ],
      "metadata": {
        "id": "F_gGqhuPPMDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim scikit-learn"
      ],
      "metadata": {
        "id": "g-6WAkqPPUs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('final_car_data.csv', on_bad_lines='skip', sep=',')\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "metadata": {
        "id": "qlfFFTyjxFe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "xkqUy3kkPgMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_features_data = data.astype(str)\n",
        "car_features_list = data.iloc[:, :].values.tolist()\n",
        "model = Word2Vec(car_features_list, vector_size=100, window=5, min_count=1, workers=4)\n",
        "model.save(\"word2vec_model_similarity\")"
      ],
      "metadata": {
        "id": "DMrbshSXPXIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_features_data = data.astype(str)\n",
        "car_features_list = data.iloc[:, :].values.tolist()\n",
        "model = Word2Vec.load(\"word2vec_model_similarity\")\n",
        "\n",
        "def calculate_similarity(vec1, vec2):\n",
        "    return cosine_similarity([vec1], [vec2])[0][0]\n",
        "\n",
        "def get_word_vector(feature):\n",
        "    return model.wv[feature]\n",
        "\n",
        "def get_average_vector(features):\n",
        "    vectors = [get_word_vector(feature) for feature in features if feature in model.wv]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "car_vectors_list = []\n",
        "\n",
        "for index, row in car_features_data.iterrows():\n",
        "    car_features = row.tolist()\n",
        "    car_vector = get_average_vector(car_features)\n",
        "    car_vectors_list.append(car_vector)\n",
        "\n",
        "columns = [f\"feature_{i}\" for i in range(len(car_vectors_list[0]))]\n",
        "car_vectors_data = pd.DataFrame(car_vectors_list, columns=columns)\n",
        "car_vectors_data.to_csv(\"car_vectors_similarity.csv\", index=False)\n",
        "\n",
        "def calculate_similarity(vec1, vec2):\n",
        "    return cosine_similarity([vec1], [vec2])[0][0]\n",
        "\n",
        "car_vectors_data = pd.read_csv('car_vectors_similarity.csv')\n",
        "user_preference = car_features_list[0]\n",
        "user_preference = [str(element) for element in user_preference]\n",
        "user_preference_vector = get_average_vector(user_preference)\n",
        "\n",
        "car_similarities = {}\n",
        "for index, row in car_vectors_data.iterrows():\n",
        "    car_vector = row.tolist()\n",
        "    similarity = calculate_similarity(user_preference_vector, car_vector)\n",
        "    car_similarities[index] = {'similarity': similarity}\n",
        "\n",
        "sorted_cars = sorted(car_similarities.items(), key=lambda x: x[1]['similarity'], reverse=True)\n",
        "\n",
        "print(\"Ranked cars based on user preference similarity:\")\n",
        "for car_index, car_info in sorted_cars[:100]:\n",
        "    print(f\"Similarity: {car_info['similarity']:.2f}, Car: {data.iloc[car_index]}\")"
      ],
      "metadata": {
        "id": "0trDX9iQPpy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K Means"
      ],
      "metadata": {
        "id": "aoJgBDYhQdGy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "bPSVqUkCQltd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1HExhOhHdXi"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('final_car_data.csv', on_bad_lines='skip', sep=',')\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "car_data = data\n",
        "car_data = data.drop(columns=['Make', 'Model', 'baseModel', 'Image', 'Cylinders', 'Drive', 'Fuel Type', 'Transmission', 'Electric motor', 'Annual Fuel Cost For Fuel Type1'])"
      ],
      "metadata": {
        "id": "9LA87CtaQywQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_features_data = car_data.astype(str)\n",
        "car_features_list = car_data.iloc[:, :].values.tolist()\n",
        "model = Word2Vec(car_features_list, vector_size=100, window=5, min_count=1, workers=4)\n",
        "model.save(\"word2vec_model_cluster\")"
      ],
      "metadata": {
        "id": "ywXVT4FYQzUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_features_data = car_data.astype(str)\n",
        "car_features_list = car_data.iloc[:, :].values.tolist()\n",
        "model = Word2Vec.load(\"word2vec_model_cluster\")\n",
        "\n",
        "def calculate_similarity(vec1, vec2):\n",
        "    return cosine_similarity([vec1], [vec2])[0][0]\n",
        "\n",
        "def get_word_vector(feature):\n",
        "    return model.wv[feature]\n",
        "\n",
        "def get_average_vector(features):\n",
        "    vectors = [get_word_vector(feature) for feature in features if feature in model.wv]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "car_vectors_list = []\n",
        "for index, row in car_features_data.iterrows():\n",
        "    car_features = row.tolist()\n",
        "    car_vector = get_average_vector(car_features)\n",
        "    car_vectors_list.append(car_vector)\n",
        "\n",
        "columns = [f\"feature_{i}\" for i in range(len(car_vectors_list[0]))]\n",
        "car_vectors_data = pd.DataFrame(car_vectors_list, columns=columns)\n",
        "car_vectors_data.to_csv(\"car_vectors_cluster.csv\", index=False)"
      ],
      "metadata": {
        "id": "TWn_7kbKQ6FL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_vectors_data = pd.read_csv(\"car_vectors_cluster.csv\")\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "df_normalized = pd.DataFrame(scaler.fit_transform(car_vectors_data), columns=car_vectors_data.columns)\n",
        "\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "    kmeans.fit(car_vectors_data)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
        "plt.title('Elbow Method')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.xticks(np.arange(1, 11, 1))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1zH4uLIhfav1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_clusters = 4\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "cluster_labels = kmeans.fit_predict(car_vectors_data)"
      ],
      "metadata": {
        "id": "yW3wE_5EQ_V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('kmeans_model.pkl', 'wb') as f:\n",
        "    pickle.dump(kmeans, f)\n",
        "\n",
        "data['cluster_label'] = cluster_labels\n",
        "car_vectors_data['cluster_label'] = cluster_labels\n",
        "\n",
        "data.to_csv(\"car_clusters.csv\")\n",
        "car_vectors_data.to_csv(\"car_vectors_cluster_label.csv\")"
      ],
      "metadata": {
        "id": "uHtPumICRHPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "_pnCxkvLpWzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('kmeans_model.pkl', 'rb') as f:\n",
        "    loaded_kmeans = pickle.load(f)"
      ],
      "metadata": {
        "id": "UWm6W83kRVHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_user_preference = {\n",
        "  'City Mpg For Fuel Type1': [\"15\"],\n",
        "  'Co2 Fuel Type1': [\"500\"],\n",
        "  'Vehicle Size Class': [\"Standard Pickup Trucks 4WD\"],\n",
        "  'Year': [\"2015\"],\n",
        "  'ATV Type': [\"Petrol\"],\n",
        "  'Price': [\"$500,000\"]\n",
        "}\n",
        "df = pd.DataFrame(data_user_preference)\n",
        "\n",
        "\n",
        "centroid_vectors = loaded_kmeans.cluster_centers_\n",
        "user_preference_vector = get_average_vector(df.iloc[0])\n",
        "df = pd.DataFrame(user_preference_vector).T\n",
        "df.columns = [f'feature_{i}' for i in range(len(df.columns))]\n",
        "\n",
        "distances = pairwise_distances(df.values.tolist(), centroid_vectors, metric='euclidean')\n",
        "closest_center_index = np.argmin(distances)\n",
        "\n",
        "print(distances)\n",
        "print(f\"User preference is closest to Cluster {closest_center_index}\")"
      ],
      "metadata": {
        "id": "hS8H9292RW3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_vectors_cluster_label = pd.read_csv('car_vectors_cluster_label.csv')\n",
        "\n",
        "similiar_cars_vectors = car_vectors_cluster_label.loc[car_vectors_cluster_label['cluster_label'] == closest_center_index]\n",
        "car_data = similiar_cars_vectors.drop(columns=['Unnamed: 0', 'cluster_label'])\n",
        "\n",
        "def calculate_similarity(vec1, vec2):\n",
        "  return cosine_similarity([vec1], [vec2])[0][0]\n",
        "\n",
        "car_similarities = {}\n",
        "for index, row in car_data.iterrows():\n",
        "  car_vector = row.tolist()\n",
        "  similarity = calculate_similarity(user_preference_vector, car_vector)\n",
        "  car_similarities[index] = {'similarity': similarity}\n",
        "\n",
        "sorted_cars = sorted(car_similarities.items(), key=lambda x: x[1]['similarity'], reverse=True)\n",
        "print(sorted_cars)"
      ],
      "metadata": {
        "id": "rktPA4hpho04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Factorization"
      ],
      "metadata": {
        "id": "4-_LwTZWwYnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating User Data"
      ],
      "metadata": {
        "id": "MDtvz1YKye38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "car_data = pd.read_csv(\"car_clusters.csv\")\n",
        "car_data.head()"
      ],
      "metadata": {
        "id": "DhQEO0Z4x0tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_data = car_data.rename(columns={'Unnamed: 0': 'Index'})\n",
        "car_data.head()"
      ],
      "metadata": {
        "id": "5quyydKwx4Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = 610  # Total number of users\n",
        "user_ids = range(0, num_users + 1)\n",
        "user_data = pd.DataFrame(columns=['userId', 'carId', 'rating'])\n",
        "\n",
        "for user_id in user_ids:\n",
        "    user_specific_cluster = np.random.randint(0, 4)\n",
        "\n",
        "    cluster_weights = {0: np.random.uniform(0.1, 0.3),\n",
        "                       1: np.random.uniform(0.1, 0.3),\n",
        "                       2: np.random.uniform(0.1, 0.3),\n",
        "                       3: np.random.uniform(0.1, 0.3)}\n",
        "\n",
        "    cluster_weights[user_specific_cluster] *= 25\n",
        "\n",
        "    cluster_probs = np.array([cluster_weights[cluster] for cluster in car_data['cluster_label']])\n",
        "\n",
        "    num_entries = np.random.randint(5, 100)\n",
        "    sampled_cars = np.random.choice(car_data['Index'], size=num_entries, p=cluster_probs / np.sum(cluster_probs))\n",
        "\n",
        "    ratings = []\n",
        "    for car_id in sampled_cars:\n",
        "        if car_data.loc[car_data['Index'] == car_id, 'cluster_label'].iloc[0] == user_specific_cluster:\n",
        "            rating = np.random.choice([3, 4, 5], p=[0.5, 0.2, 0.3])\n",
        "        else:\n",
        "            rating = np.random.choice([1, 2], p=[0.6, 0.4])\n",
        "        ratings.append(rating)\n",
        "\n",
        "    user_data = pd.concat([user_data, pd.DataFrame({'userId': [user_id] * num_entries,\n",
        "                                                    'carId': sampled_cars,\n",
        "                                                    'rating': ratings})], ignore_index=True)\n",
        "\n",
        "user_data = user_data.sample(frac=1).reset_index(drop=True)\n",
        "print(user_data.head())"
      ],
      "metadata": {
        "id": "p4HmvldhyABJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_data.info()"
      ],
      "metadata": {
        "id": "udOjAiKAyLza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_data = user_data.sort_values(by=\"userId\")\n",
        "\n",
        "def count_values(df):\n",
        "    counts = {}\n",
        "    for column in df.columns:\n",
        "        counts[column] = df[column].value_counts()\n",
        "    return counts\n",
        "\n",
        "counts = count_values(user_data)\n",
        "print(counts)"
      ],
      "metadata": {
        "id": "GoUPgX-TyQRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_data.head()\n",
        "user_data.to_csv('ratings.csv', index = False)"
      ],
      "metadata": {
        "id": "4yRJ9SHIyVZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "O-9kj2a3yjE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "\n",
        "from scipy.sparse import vstack\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "VKriFpcNylw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_ratings = pd.read_csv('ratings.csv')\n",
        "print('Shape Car-ratings:\\t{}'.format(car_ratings.shape))\n",
        "car_ratings.head()"
      ],
      "metadata": {
        "id": "9kVb4dtTypXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_p = car_ratings.pivot_table(index='userId', columns='carId', values='rating')\n",
        "df_p.sample(6)"
      ],
      "metadata": {
        "id": "KNfjHmPry9Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = car_ratings\n",
        "user_ids = df[\"userId\"].unique().tolist()\n",
        "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
        "car_ids = df[\"carId\"].unique().tolist()\n",
        "car2car_encoded = {x: i for i, x in enumerate(car_ids)}\n",
        "car_encoded2car = {i: x for i, x in enumerate(car_ids)}\n",
        "df[\"user\"] = df[\"userId\"].map(user2user_encoded)\n",
        "df[\"car\"] = df[\"carId\"].map(car2car_encoded)\n",
        "\n",
        "num_users = len(user2user_encoded)\n",
        "num_cars = len(car_encoded2car)\n",
        "\n",
        "df = df.sample(frac=1, random_state=42)\n",
        "x = df[[\"user\", \"car\"]].values\n",
        "y = df[\"rating\"].apply(lambda x: (x - 0.5) / (4.5)).values\n",
        "\n",
        "train_indices = int(0.9 * df.shape[0])\n",
        "\n",
        "x_train, x_val, x_test, y_train, y_val, y_test = (\n",
        "    x[:train_indices],\n",
        "    x[train_indices:-1000],\n",
        "    x[-1000:],\n",
        "    y[:train_indices],\n",
        "    y[train_indices:-1000],\n",
        "    y[-1000:],\n",
        ")"
      ],
      "metadata": {
        "id": "3_B-3d_KzRi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size= 50\n",
        "\n",
        "user_id_input = Input(shape=[1], name='user')\n",
        "car_id_input = Input(shape=[1], name='car')\n",
        "\n",
        "user_embedding = Embedding(output_dim=embedding_size,\n",
        "                           input_dim=num_users,\n",
        "                           input_length=1,\n",
        "                           embeddings_initializer=\"he_normal\",\n",
        "                           embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "                           name='user_embedding')(user_id_input)\n",
        "car_embedding = Embedding(output_dim=embedding_size,\n",
        "                            input_dim=num_cars,\n",
        "                            input_length=1,\n",
        "                            embeddings_initializer=\"he_normal\",\n",
        "                            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
        "                            name='car_embedding')(car_id_input)\n",
        "\n",
        "user_vector = Reshape([embedding_size])(user_embedding)\n",
        "car_vector = Reshape([embedding_size])(car_embedding)\n",
        "\n",
        "concat = Concatenate()([user_vector, car_vector])\n",
        "dense1 = Dense(256)(concat)\n",
        "dense = Dropout(0.2)(dense1)\n",
        "y = Dense(1, activation=\"sigmoid\")(dense) # The sigmoid activation forces the rating to between 0 and 1\n",
        "\n",
        "model = Model(inputs=[user_id_input, car_id_input], outputs=y)\n",
        "model.compile(loss='mse',  optimizer = 'adam')\n",
        "\n",
        "history = model.fit(\n",
        "            x = [x_train[:,0],x_train[:,1]],\n",
        "            y = y_train,\n",
        "            batch_size=256,\n",
        "            epochs=4,\n",
        "            validation_data = ([x_val[:,0], x_val[:,1]], y_val),\n",
        "          )"
      ],
      "metadata": {
        "id": "shklfgc9zBs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "QbN-rIpkzdJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"Model loss\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"train\", \"test\"], loc=\"upper right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0XgmqOKCzgb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict([x_test[:,0], x_test[:,1]])\n",
        "y_true =  y_test\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_pred=y_pred, y_true=y_true))\n",
        "print('\\n\\nTesting Result : {:.4f} RMSE'.format(rmse))"
      ],
      "metadata": {
        "id": "DyRUXwiNzkha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p , a = (model.predict([x_test[:15,0], x_test[:15,1]]) , y_test[:15])\n",
        "print(\"Ratings are Normalized between 0 and 1 (1 - 5)\")\n",
        "for i in range(len(p)):\n",
        "    print(\"Predicted rating is : \"+ str(np.round(p[i],2)) +\"        Actual rating was : \"+ str(round(a[i],2)) )"
      ],
      "metadata": {
        "id": "yo1EkUQMzoTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations(user_id):\n",
        "    cars_watched_by_user = df[df.userId == user_id]\n",
        "    cars_not_watched = car_df[~car_df[\"carId\"].isin(cars_watched_by_user.carId.values)][\"carId\"]\n",
        "    cars_not_watched = list(cars_not_watched)\n",
        "    user_car_array = np.hstack(([user_id] * len(cars_not_watched), cars_not_watched))\n",
        "\n",
        "    ratings = model.predict([np.array(user_car_array)[:, 0], np.array(user_car_array)[:, 1]]).flatten()\n",
        "\n",
        "    top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "    recommended_car_ids = [cars_not_watched[x] for x in top_ratings_indices]\n",
        "\n",
        "    print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "    print(\"=\" * 36)\n",
        "    print(\"Cars with high ratings from user\")\n",
        "    print(\"-\" * 34)\n",
        "    top_cars_user = cars_watched_by_user.sort_values(by=\"rating\", ascending=False).head(5).carId.values\n",
        "    car_df_rows = car_df[car_df[\"carId\"].isin(top_cars_user)]\n",
        "    for row in car_df_rows.itertuples():\n",
        "        print(row)\n",
        "\n",
        "    print(\"-\" * 30)\n",
        "    print(\" Top 10 car recommendations\")\n",
        "    print(\"-\" * 30)\n",
        "    recommended_cars = car_df[car_df[\"carId\"].isin(recommended_car_ids)]\n",
        "    for row in recommended_cars.itertuples():\n",
        "        print(row)"
      ],
      "metadata": {
        "id": "0smvZ3kKz83n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "car_df = pd.read_csv('/content/final_car_data.csv')\n",
        "car_df['carId'] = car_df.index\n",
        "\n",
        "def get_recommendations(user_id):\n",
        "      cars_watched_by_user = df[df.userId == user_id]\n",
        "      cars_not_watched = car_df[\n",
        "          ~car_df[\"carId\"].isin(cars_watched_by_user.carId.values)][\"carId\"]\n",
        "      cars_not_watched = list(\n",
        "          set(cars_not_watched).intersection(set(car2car_encoded.keys()))\n",
        "      )\n",
        "      cars_not_watched = [[car2car_encoded.get(x)] for x in cars_not_watched]\n",
        "      user_encoder = user2user_encoded.get(user_id)\n",
        "      user_car_array = np.hstack(\n",
        "          ([[user_id]] * len(cars_not_watched), cars_not_watched)\n",
        "      )\n",
        "\n",
        "      ratings = model.predict([user_car_array[:,0], user_car_array[:,1]]).flatten()\n",
        "\n",
        "      top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
        "      recommended_car_ids = [\n",
        "          car_encoded2car.get(cars_not_watched[x][0]) for x in top_ratings_indices\n",
        "      ]\n",
        "\n",
        "      print(\"Showing recommendations for user: {}\".format(user_id))\n",
        "      print(\"=\" * 36)\n",
        "      print(\"Cars with high ratings from user\")\n",
        "      print(\"-\" * 34)\n",
        "      top_cars_user = (\n",
        "          cars_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
        "          .head(5)\n",
        "          .carId.values\n",
        "      )\n",
        "      car_df_rows = car_df[car_df[\"carId\"].isin(top_cars_user)]\n",
        "      for row in car_df_rows.itertuples():\n",
        "          print(row)\n",
        "\n",
        "      print(\"-\" * 30)\n",
        "      print(\" Top 10 car recommendations\")\n",
        "      print(\"-\" * 30)\n",
        "      recommended_cars = car_df[car_df[\"carId\"].isin(recommended_car_ids)]\n",
        "      for row in recommended_cars.itertuples():\n",
        "          print(row)"
      ],
      "metadata": {
        "id": "dF6ddcmMz9-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = 611\n",
        "\n",
        "user_data = pd.DataFrame(columns=['userId', 'carId', 'rating'])\n",
        "\n",
        "user_specific_cluster = np.random.randint(0, 4)\n",
        "\n",
        "cluster_weights = {0: np.random.uniform(0.1, 0.3),\n",
        "                    1: np.random.uniform(0.1, 0.3),\n",
        "                    2: np.random.uniform(0.1, 0.3),\n",
        "                    3: np.random.uniform(0.1, 0.3)}\n",
        "\n",
        "cluster_weights[user_specific_cluster] *= 25\n",
        "\n",
        "cluster_probs = np.array([cluster_weights[cluster] for cluster in car_data['cluster_label']])\n",
        "\n",
        "num_entries = np.random.randint(5, 100)\n",
        "sampled_cars = np.random.choice(car_data['Index'], size=num_entries, p=cluster_probs / np.sum(cluster_probs))\n",
        "\n",
        "ratings = []\n",
        "for car_id in sampled_cars:\n",
        "    if car_data.loc[car_data['Index'] == car_id, 'cluster_label'].iloc[0] == user_specific_cluster:\n",
        "        rating = np.random.choice([3, 4, 5], p=[0.5, 0.2, 0.3])\n",
        "    else:\n",
        "        rating = np.random.choice([1, 2], p=[0.6, 0.4])\n",
        "    ratings.append(rating)\n",
        "\n",
        "user_data = pd.concat([user_data, pd.DataFrame({'userId': user_id,\n",
        "                                                'carId': sampled_cars,\n",
        "                                                'rating': ratings})], ignore_index=True)"
      ],
      "metadata": {
        "id": "WGU3zKSl0EJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_data\n",
        "user_data.to_csv('user_ratings.csv', index = False)"
      ],
      "metadata": {
        "id": "vRJSRHWl0FaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_df = pd.read_csv('/content/ratings.csv')\n",
        "new_user_ratings_df = pd.read_csv('/content/user_ratings.csv')\n",
        "print('Shape Existing-ratings:\\t{}'.format(existing_df.shape))\n",
        "print('Shape New-ratings:\\t{}'.format(new_user_ratings_df.shape))"
      ],
      "metadata": {
        "id": "uLO8kraX0IIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_ratings_df.head()"
      ],
      "metadata": {
        "id": "SPzo3IMm0JkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_df = pd.concat([existing_df, new_user_ratings_df], ignore_index=True)\n",
        "car_ratings = combined_df\n",
        "print('Shape Car-ratings:\\t{}'.format(car_ratings.shape))"
      ],
      "metadata": {
        "id": "mo5_7_xR0L4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}